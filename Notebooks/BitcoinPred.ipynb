{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://drive.google.com/drive/folders/0BzqCBdvJ6j-nUzRZckRJUVJwY00\">link to the data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "df = pd.read_csv('C:/Users/Thomas/Desktop/features.csv')\n",
    "df.change = df.change.round()\n",
    "df = df.drop(\"date\", 1)\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1:].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130222</td>\n",
       "      <td>16288.048305</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.131572</td>\n",
       "      <td>14672.506247</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.162661</td>\n",
       "      <td>13981.732830</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.156032</td>\n",
       "      <td>13375.030012</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178366</td>\n",
       "      <td>13296.763133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.187558</td>\n",
       "      <td>13296.883238</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.186321</td>\n",
       "      <td>12760.569263</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.154728</td>\n",
       "      <td>10882.865429</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.171397</td>\n",
       "      <td>10721.842279</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.215130</td>\n",
       "      <td>10211.398486</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment        volume  change\n",
       "0   0.130222  16288.048305    -2.0\n",
       "1   0.131572  14672.506247    -4.0\n",
       "2   0.162661  13981.732830    -2.0\n",
       "3   0.156032  13375.030012    -3.0\n",
       "4   0.178366  13296.763133     1.0\n",
       "5   0.187558  13296.883238     2.0\n",
       "6   0.186321  12760.569263     1.0\n",
       "7   0.154728  10882.865429    43.0\n",
       "8   0.171397  10721.842279     0.0\n",
       "9   0.215130  10211.398486     1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LogisticRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ -6.24421833e-01  -2.32338622e-05]\n",
      " [ -5.61911588e-01  -7.58401192e-05]\n",
      " [ -6.78096531e-01  -8.46565566e-06]\n",
      " [ -5.74999731e-01  -3.91546373e-05]\n",
      " [ -3.96803706e-01  -1.50090250e-04]\n",
      " [ -2.29427434e-01  -2.43527729e-04]\n",
      " [ -2.66273706e-01  -2.63243410e-04]\n",
      " [ -5.96702268e-01  -2.85098206e-05]\n",
      " [ -6.97625916e-01  -6.37548643e-06]\n",
      " [ -5.60090093e-09  -4.77368878e-04]\n",
      " [ -7.11431652e-01   1.09727408e-05]\n",
      " [ -6.14697535e-01  -1.76573667e-05]\n",
      " [ -2.95844513e-01  -1.26377318e-04]\n",
      " [ -6.72442194e-01  -3.22636182e-06]\n",
      " [ -5.41971786e-01  -7.37302647e-05]\n",
      " [ -6.00544765e-01  -3.64903320e-05]\n",
      " [ -6.72219966e-01  -3.84266620e-06]\n",
      " [ -5.87600077e-01   1.17368995e-07]\n",
      " [ -5.82896416e-01   2.27977203e-07]\n",
      " [ -3.78408957e-01  -4.02630362e-05]\n",
      " [ -4.26537662e-01  -1.12143931e-05]\n",
      " [ -2.62688874e-01  -5.47448949e-05]\n",
      " [ -1.46948164e-01  -8.02812161e-05]\n",
      " [ -3.50049179e-02  -1.17750373e-04]\n",
      " [ -1.17187775e-09  -1.10416468e-04]\n",
      " [ -5.85907813e-06  -1.00750440e-04]\n",
      " [ -3.78116912e-10  -5.77041667e-05]\n",
      " [ -1.20672920e-10  -4.49005767e-05]\n",
      " [ -3.74907087e-10  -5.49102349e-05]\n",
      " [ -7.03774476e-10  -7.86253511e-05]\n",
      " [ -5.51940883e-06  -1.01671959e-04]\n",
      " [ -1.33609864e-01  -7.14378674e-05]\n",
      " [ -1.51179231e-01  -8.83274407e-05]\n",
      " [ -2.57024757e-01  -4.74961362e-05]\n",
      " [ -3.17164361e-01  -4.69024014e-05]\n",
      " [ -3.90629737e-01  -3.90935368e-05]\n",
      " [ -3.79069497e-01  -4.61644504e-05]\n",
      " [ -4.09396419e-01  -4.78131028e-05]\n",
      " [ -5.01389430e-01  -5.13695620e-05]\n",
      " [ -6.27728342e-01  -1.47510422e-05]\n",
      " [ -3.08723267e-01  -1.20068287e-04]\n",
      " [ -5.15893376e-02  -3.07426303e-04]\n",
      " [ -6.22797334e-01  -3.13297725e-05]\n",
      " [ -5.60635131e-01  -6.38948535e-05]\n",
      " [ -2.30429502e-01  -2.25166162e-04]\n",
      " [ -4.44611732e-01  -1.21669991e-04]\n",
      " [ -6.60926230e-01  -3.04094535e-06]\n",
      " [ -1.28586247e-05  -4.43242490e-04]\n",
      " [ -1.02259100e-05  -4.52425146e-04]\n",
      " [ -4.63930215e-01  -1.14359372e-04]\n",
      " [ -5.22888959e-01  -6.63717906e-05]\n",
      " [ -7.14187880e-01   6.98915247e-06]\n",
      " [ -3.93077758e-09  -5.24483319e-04]\n",
      " [ -6.89418841e-01  -4.14668204e-06]]\n",
      "Mean squared error: 38.55\n",
      "Variance score: -0.23\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LogisticRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -9.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      " -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      " -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -9.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -9.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -9.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -9.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -9.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0. -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -9.\n",
      "  -0.  -0.  -0.  -0.  -0. -17.  -9.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. -17.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -9.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -9.\n",
      "  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.]\n",
      "[ 10.  -3.   1.  -0.   1.  -1.  -2.  -7.  -1.   1.  -2.   0.   1.   2.  -0.\n",
      "   0. -10.   0.  -0.   3.   1.   1.   2.  10.  -1.   2.  -2.  -1.   1.  -2.\n",
      "   0.  -0.   1.  -0.   1.  -1.  -1.  -1.   0.   1.   4.  -0.  -2.  -0.   0.\n",
      "   2.  -2.  -0.   1.  -0.  -3.   1.  -1.  -0. -38.   3.  -0.  -1.   6.  -4.\n",
      "   2.  -0.   6.  -0.   4.  -5.  -3.   3.   2.   0. -13.   1.   5.   3.  -1.\n",
      "  -2.  -5. -21.   0.  -1.   2.   2.   1.  -2.  -1.  -0.   4.   3.   2.  -3.\n",
      "  -1.  -5.   8.  -2.  -1.   2.   1.   2.  -1.   1.  -4.  -3.  -3.  -1.   1.\n",
      "  -1.  -0.   3.   1.   0.   1.   4.  -1.   5.   1.  11.   0.  -5.   3.  -1.\n",
      "   0.   2.  -1.   0.  -0.  -1.  12.   1.  -0.   1. -15.  -0.   2.  -0.   2.\n",
      "  -2.  -0.  -3.   1.  -3.   3.  -1.   0.   1.  -2.   1.   2.   1.   2.   0.\n",
      "   3.  -3.  -0.  -8.   1.  -6.  -1.  -0.  -2.  -0.  -1.   1.   3. -23.   2.\n",
      "   8.   1.  -2.   7.  -2.   2.  -1.  -0.  -1. -21.   9.  -2.   1.   2.  -0.\n",
      "  -2.  -1.   0.   0.   3.  -1.  -4.  -3.  -1.  -0.   2.  -1.  -1.  -1.   1.\n",
      " -30.  12.   8.  -0.  -0.  -3.   1.  -2.  -6.   0.  -2.  -0.   1. -10.   3.\n",
      " -15.  -2.   1.   0.   0.   4.   0. -11.  -0.   1.   2.  -0.   0.   3.   1.\n",
      "   0.  -0.  -1.   1.  -1.  -1.   0.  -1.   0.   3.  -1.  -4.  -1.   4.   1.\n",
      "   2.  -0.  -2.   4.   0.  -1.   2.   8.  -1.  -2.   1.   2.  -1.  -2.  -5.\n",
      "  -1.  -2.  -4.   0.   0.  -0.   0.   2.  -1.  -0.   1. -26.   8.   5.  -2.\n",
      "  -2.  -1.  -1.  -1.   1.  -0.   1.   0.   0.   5.   1.  13.  -1.  -7.  -3.\n",
      "   0.  -2.  10.   1.  -1.   1.   0.  -9.   3.  -2.  -1.   1.  -0.   0.   1.\n",
      "   0.  -8.  -1.   6. -10.   1.  -1.  -1.  -3.  -0.  -4.   1.   5.   4.  -0.\n",
      "  -2.  19.   3.  -2.   2.  14.   6.  -1.  -1.   0.  -4.   0.   0.   1.  -4.\n",
      "   4.  -2.   0.  -0.  -2.   7.   1.  -1.  12.  -1.  -3.  -2. -12.  -4.  -8.\n",
      "   5.  -4.  -0.  -1.   1.  -1.   0.   3.  -6.   2.   2.  -2.   3.  -0.  -0.\n",
      "   1.   1.  -0.  15.  -1.   1.  -1.  -1.  -1.  -1.   1.   1.  -1.  -5.  14.\n",
      "  -3.   1.   1.   3.   7.   1.  -0.   0.   0.   0.  -1.  -1.  -8.   1.  22.\n",
      "  -1.   1.   4.  -0.   1.   1.  -2.  -3.   1.   0.  -1.  -1.   1.  -8.  -0.\n",
      "   1.   0.  -1.   3.   1.   1. -33.   4.   4.   1.   0.  -1.   0.   1.  -6.\n",
      "  -1.  -0.   1.   1.   1.   0.  -1.  -0.   0.  -2.  13.  -5.  10.   0.   1.\n",
      "   4.   6.  -0.   3.  -3.   0.   1.  -1.   1.   0.  -1.   0.  -2.   2.   1.\n",
      "   0.   1.  -3.  -1.   1.  -2.  -1.   1.   1.   2.   1.  -0.  -2.   1.   1.\n",
      "   3.   0.   0.  -2.  -3.   2.   9.   3.  -1.   5.  -3.  15.  -0.  -1.  -1.\n",
      "  -0.  -1.  13.  -4.  -0.  -8.   1.   1.  -3.   1.   1.   0.   4.  -1.   5.\n",
      "   1.   0.   3. -10.   0.  -5.  -1.  -1.  -2.   1.  -1.  -0.   2.  -4.   1.\n",
      "  -2.  -1.  -2.   0.   1.   2.  -1.   1.   2. -18.  -2.   1.  -1.   4.   1.\n",
      "  -1.  -4.   1.  -2.   0.   2.  -1.  -1.   0.  -0.   1.  -0.   1.  -8.   1.\n",
      "   4.   3.  -1.  -0.   1.   0.   1.  -4.  -3.  -3.  -0.   5.   1.   1. -19.\n",
      "   3.   0.  -1.  -0.   2.   2.  -5.   2.   4.   0.  -0.   0.   4.   1.   0.\n",
      "  -0.   1.   2.   1.  -2.   1.  -1.  -1.  -0.   1.  -1.  -1.   3.  -0.  -1.\n",
      "   3.  -2.  -0.   1.  -2.  -1.  -1.   0.   1.  -0.  -1.  -0.  -0.   9.   9.\n",
      "   7.   2.  -2.   9.   1.  -1.   0.   3.  -3.   2.  -1.   0.   2.   0.  -6.\n",
      "  -2.   2.   2.   3.   1.  -1.   2.   3.   1.  12.   5.  -2.  -1.   1.  -1.\n",
      "   0.   1.  -2.   5.  -1.   0.   0.   6.   3.  -1.   3.   1.  -6.  -1.  -1.\n",
      "  -1.   1.   0.  -8.   1.  -0.  -4.   1.  -0.   4.  -3.   1.  -1.  -1.   1.\n",
      "  -1.  10.   3.   1.   2.  -1.  -0.  -0.  -1.  -4.   3.   0.  -5.  -2.  -0.\n",
      "  -2.   1.  -1.   2.  -1.   1.   0.   1.  -2.  -1.   0.   3.  -0.  -0.   3.\n",
      "   4.   3.   0.  -2.  -3.   2.  -1.  -1.   2.  -1.  -0.   0.   2.   1.  -0.\n",
      "   6.   3.   4.  -1.   1.   1.   1.  -0.  31.  -3.   1.   0.  -0.  -3.  -1.\n",
      "   1.  13.   1.   0.  -2.  -2.  -7.  -0.  -1.  -2.   0.   2.   1.   0.  -5.\n",
      "   1.   1.   2.   3.   1.  -4.   1.   0.  -0.  -1.   3.   3.   0.  -2.  -1.\n",
      "   1.  -1.   2.  -1.   8.  -0.   2.  -1.  -2.   3.   1.   0.   7.   1.  -0.\n",
      "   1.  -3.  57.  -1. -68.  -0.   1.   5.  -1.  -4.   7.   0.   3.   8.  15.\n",
      "  -1.   1.  -1.  -1.  -1.   5. -29.   0.   0.  -0.  -0.   0.   1.   1.  -2.\n",
      "  -2.   0.  -1.  12.  -1.  -0.   2.  -1.   2.  -1.   3.  -5.   0.  -6.  -3.\n",
      "  -0.  -1.   0.   1.  -3.  -0.  -2.   1.  -7.   7.   2.   1.  -0.  -0.  -0.\n",
      "  -0.  -0.  -2.   2.   4. -18.  -1.   1.  -0.  -1.   1.  -1.   1.  -3.   1.\n",
      "  13.  -1.   3.   1.   0.  -0.   9.  -1.   5.   0.   2.   0.  -2.  -0.  -2.\n",
      "  -1.   3.  20.   0.   1.   4.  -1.  -0.   2.   4.  -1.  -1.   0.   1.  -0.\n",
      "   5.   3.  -1.   2.  -0.  -1.   0.  -1.  -2.   1.  -1.  20.  -1. -13.  -1.\n",
      "   1.   1.  -2.   2.   1.  -1.   1.  -8.  -1.  -3.   4.   2.]\n",
      "The error is  0.779264214047\n"
     ]
    }
   ],
   "source": [
    "error = np.mean(y_pred != y_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "print(\"The error is \", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
